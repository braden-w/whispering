# Reddit r/YCombinator Post

## Status: âœ… POSTED

## Posted URL: https://www.reddit.com/r/ycombinator/comments/1lu4hyq/how_i_code_5x_faster_by_talking_to_my_computer/

## Title
How I code 5x faster by talking to my computer

## Post Content

Been experimenting with a new coding workflow that's made me about 5x more productive: I split Claude Code (more recently `opencode`) five ways, then use voice-activated dictation to manage all of them simultaneously.

The key innovation is completely hands-free operation - I don't even press a key. I can be typing or moving my mouse on one task, and the moment I have a thought, I just start speaking out loud. This zero-friction capture is game-changing.

I speak naturally while coding, get instant transcription, and paste. No carefully crafted prompts - I just talk like I'm explaining to a colleague. Claude just gets it.

The speed difference is insane. When I'm deep in a problem, I can ramble about what I'm trying to solve and Claude picks up all the context. I stay in flow state and can manage multiple complex refactors in parallel.

What surprised me most is how it changes your thinking. When you're not worried about syntax or typing speed, you can focus entirely on architecture and logic. I've built entire features while pacing around my apartment.

Here's a 3-min demo of the workflow: https://www.youtube.com/watch?v=tP1fuFpJt7g&t=8s

For anyone who wants to try this - I use Whispering, an open-source transcription app I built. You bring your own API key (Groq is $0.02/hour) and your audio goes directly to them. No middleman servers.

Launched it today on HN and Reddit. The response has been interesting - people seem more excited about the workflow than the cost savings.

GitHub: https://github.com/epicenter-so/epicenter

Anyone else experimenting with voice-driven development? What's your workflow?